# src/engines/extractor_engine.py
from __future__ import annotations
from pathlib import Path
import subprocess
import pyarrow as pa
import pyarrow.csv as csv


class ExtractorEngine:
    """
    å·¥ä¸šçº§ CSV Extractorï¼š
    - streaming 7z
    - åªè¯» header ä¸€æ¬¡
    - å¼ºåˆ¶æ‰€æœ‰åˆ— string
    """

    @staticmethod
    def _read_header(zfile: Path) -> list[str]:
        """
        åªè¯»å– CSV headerï¼ˆç¬¬ä¸€è¡Œï¼‰
        """
        proc = subprocess.Popen(
            ["7z", "x", "-so", str(zfile)],
            stdout=subprocess.PIPE,
        )

        # åªè¯»ç¬¬ä¸€è¡Œ
        header = proc.stdout.readline()
        proc.kill()

        # Arrow CSV é»˜è®¤ç”¨ ',' åˆ†éš”
        return header.decode("utf-8").strip().split(",")

    @staticmethod
    def open_reader(zfile: Path, streaming: bool = True):
        if not streaming:
            raise NotImplementedError("é streaming æ¨¡å¼æš‚æœªå®ç°")

        # â‘  å…ˆè¯» header
        column_names = ExtractorEngine._read_header(zfile)

        # â‘¡ å†é‡æ–°å¼€å¯ streaming reader
        proc = subprocess.Popen(
            ["7z", "x", "-so", str(zfile)],
            stdout=subprocess.PIPE,
        )

        convert_opts = csv.ConvertOptions(
            column_types={name: pa.string() for name in column_names},
            strings_can_be_null=True,
            null_values=["", " ", "NULL", "N/A", "nan"],
            quoted_strings_can_be_null=True,
        )

        read_opts = csv.ReadOptions(
            autogenerate_column_names=False,
            skip_rows=1,  # ğŸ”¥ è·³è¿‡ header è¡Œ
            column_names=column_names,
            block_size=1 << 26,  # 64MB
            use_threads=True,
        )

        return csv.open_csv(
            proc.stdout,  # binary stream
            read_options=read_opts,
            convert_options=convert_opts,
        )

    @staticmethod
    def cast_strings(batch: pa.RecordBatch) -> pa.RecordBatch:
        # ç°åœ¨åªæ˜¯ä¿é™©ï¼Œä¸æ˜¯æ•‘å‘½
        cols = [col.cast(pa.string(), safe=False) for col in batch.columns]
        return pa.record_batch(cols, batch.schema.names)
